{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from dna2vec.multi_k_model import MultiKModel\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Read fasta ####\n",
    "def read_FASTA(file_name):\n",
    "    with open(file_name, \"r\") as fn:\n",
    "        text = fn.read().split(\">\")\n",
    "    text = [x.split(\"\\n\") for x in text if x != \"\"]\n",
    "    text = [[x[0],\"\".join(x[1:]).upper()] for x in text]\n",
    "    text_dict = {line[0].split('|')[0]:line[1] for line in text}\n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = 'pretrained/dna2vec-20161219-0153-k3to8-100d-10c-29320Mbp-sliding-Xat.w2v'\n",
    "mk_model = MultiKModel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mk_model.vector(\"AAATGGTT\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code = read_FASTA(\"../../data/FINAL_DATA_1/fasta_for_test/train_fasta_gencode.fasta\")\n",
    "noncode = read_FASTA(\"../../data/FINAL_DATA_1/fasta_for_test/train_fasta_lncPedia.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vec(seq, kmer=8, max_length=13000):\n",
    "    vectors = []\n",
    "    i = 0\n",
    "    while (i<(len(seq)-kmer)) and (i<max_length):\n",
    "        tmp = seq[i:i+kmer]\n",
    "        if 'N' in tmp:\n",
    "            i+=1\n",
    "            continue\n",
    "        vec_tmp = mk_model.vector(tmp)\n",
    "        vectors.append(vec_tmp)\n",
    "        i+=1\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fogside/virtualenv/py3/lib/python3.4/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 7000\n",
    "y = np.array([1]*N + [0]*N)\n",
    "X_tmp = deepcopy(list(code.items())[:N])\n",
    "X_tmp.extend(list(noncode.items())[:N])\n",
    "len(X_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix.to_csv(\"../../data/FINAL_DATA_1/embedding_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65537, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAAAA</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.365117</td>\n",
       "      <td>0.408025</td>\n",
       "      <td>0.064311</td>\n",
       "      <td>-0.293642</td>\n",
       "      <td>0.103023</td>\n",
       "      <td>0.089713</td>\n",
       "      <td>-0.764232</td>\n",
       "      <td>-0.003985</td>\n",
       "      <td>0.107479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216967</td>\n",
       "      <td>-0.809641</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.632726</td>\n",
       "      <td>0.690164</td>\n",
       "      <td>-0.406542</td>\n",
       "      <td>0.187238</td>\n",
       "      <td>-0.626230</td>\n",
       "      <td>-0.271666</td>\n",
       "      <td>0.082561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAAAC</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.288133</td>\n",
       "      <td>0.324433</td>\n",
       "      <td>-0.366527</td>\n",
       "      <td>-0.170981</td>\n",
       "      <td>-0.025718</td>\n",
       "      <td>-0.380066</td>\n",
       "      <td>0.055025</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233300</td>\n",
       "      <td>-0.737088</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>0.639653</td>\n",
       "      <td>0.292097</td>\n",
       "      <td>-0.500181</td>\n",
       "      <td>0.094142</td>\n",
       "      <td>0.100279</td>\n",
       "      <td>-0.439565</td>\n",
       "      <td>0.160597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAAAG</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.310706</td>\n",
       "      <td>-0.153957</td>\n",
       "      <td>-0.397525</td>\n",
       "      <td>0.163247</td>\n",
       "      <td>0.102393</td>\n",
       "      <td>-0.393191</td>\n",
       "      <td>-0.149867</td>\n",
       "      <td>0.093688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132578</td>\n",
       "      <td>-0.596084</td>\n",
       "      <td>0.520723</td>\n",
       "      <td>0.664362</td>\n",
       "      <td>0.738464</td>\n",
       "      <td>-0.411244</td>\n",
       "      <td>-0.110038</td>\n",
       "      <td>-0.386498</td>\n",
       "      <td>-0.017523</td>\n",
       "      <td>-0.151797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAAAT</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.276156</td>\n",
       "      <td>0.117486</td>\n",
       "      <td>0.097248</td>\n",
       "      <td>-0.301252</td>\n",
       "      <td>-0.194590</td>\n",
       "      <td>-0.149558</td>\n",
       "      <td>-0.705774</td>\n",
       "      <td>-0.121932</td>\n",
       "      <td>0.032583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>-0.890366</td>\n",
       "      <td>0.143492</td>\n",
       "      <td>0.220740</td>\n",
       "      <td>0.490493</td>\n",
       "      <td>0.093366</td>\n",
       "      <td>-0.143799</td>\n",
       "      <td>-0.783927</td>\n",
       "      <td>-0.192266</td>\n",
       "      <td>0.223240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          code         0         1         2         3         4         5  \\\n",
       "0            0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "AAAAAAAA     1 -0.365117  0.408025  0.064311 -0.293642  0.103023  0.089713   \n",
       "AAAAAAAC     2 -0.345430  0.288133  0.324433 -0.366527 -0.170981 -0.025718   \n",
       "AAAAAAAG     3  0.000498  0.310706 -0.153957 -0.397525  0.163247  0.102393   \n",
       "AAAAAAAT     4 -0.276156  0.117486  0.097248 -0.301252 -0.194590 -0.149558   \n",
       "\n",
       "                 6         7         8    ...           90        91  \\\n",
       "0         0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "AAAAAAAA -0.764232 -0.003985  0.107479    ...    -0.216967 -0.809641   \n",
       "AAAAAAAC -0.380066  0.055025 -0.016809    ...    -0.233300 -0.737088   \n",
       "AAAAAAAG -0.393191 -0.149867  0.093688    ...    -0.132578 -0.596084   \n",
       "AAAAAAAT -0.705774 -0.121932  0.032583    ...     0.003845 -0.890366   \n",
       "\n",
       "                92        93        94        95        96        97  \\\n",
       "0         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "AAAAAAAA  0.370482  0.632726  0.690164 -0.406542  0.187238 -0.626230   \n",
       "AAAAAAAC  0.072006  0.639653  0.292097 -0.500181  0.094142  0.100279   \n",
       "AAAAAAAG  0.520723  0.664362  0.738464 -0.411244 -0.110038 -0.386498   \n",
       "AAAAAAAT  0.143492  0.220740  0.490493  0.093366 -0.143799 -0.783927   \n",
       "\n",
       "                98        99  \n",
       "0         0.000000  0.000000  \n",
       "AAAAAAAA -0.271666  0.082561  \n",
       "AAAAAAAC -0.439565  0.160597  \n",
       "AAAAAAAG -0.017523 -0.151797  \n",
       "AAAAAAAT -0.192266  0.223240  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_mer = 8\n",
    "embedding_matrix = dict()\n",
    "\"\"\"\n",
    "A -- 1\n",
    "T -- 2\n",
    "G -- 3\n",
    "C -- 4\n",
    "\n",
    "\"\"\"\n",
    "for i1 in \"ATGC\":\n",
    "    for i2 in \"ATGC\":\n",
    "        for i3 in \"ATGC\":\n",
    "            for i4 in \"ATGC\":\n",
    "                for i5 in \"ATGC\":\n",
    "                    for i6 in \"ATGC\":\n",
    "                        for i7 in \"ATGC\":\n",
    "                            for i8 in \"ATGC\":\n",
    "                                name = i1+i2+i3+i4+i5+i6+i7+i8\n",
    "                                embedding_matrix[name] = mk_model.vector(name)\n",
    "\n",
    "embedding_matrix['0'] = np.zeros((100,))\n",
    "embedding_matrix = pd.DataFrame(embedding_matrix).T\n",
    "embedding_matrix.insert(0,'code', range(0, len(embedding_matrix)))\n",
    "print(embedding_matrix.shape)\n",
    "embedding_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.365117</td>\n",
       "      <td>0.408025</td>\n",
       "      <td>0.064311</td>\n",
       "      <td>-0.293642</td>\n",
       "      <td>0.103023</td>\n",
       "      <td>0.089713</td>\n",
       "      <td>-0.764232</td>\n",
       "      <td>-0.003985</td>\n",
       "      <td>0.107479</td>\n",
       "      <td>-0.488348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216967</td>\n",
       "      <td>-0.809641</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.632726</td>\n",
       "      <td>0.690164</td>\n",
       "      <td>-0.406542</td>\n",
       "      <td>0.187238</td>\n",
       "      <td>-0.626230</td>\n",
       "      <td>-0.271666</td>\n",
       "      <td>0.082561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.288133</td>\n",
       "      <td>0.324433</td>\n",
       "      <td>-0.366527</td>\n",
       "      <td>-0.170981</td>\n",
       "      <td>-0.025718</td>\n",
       "      <td>-0.380066</td>\n",
       "      <td>0.055025</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>-0.320237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233300</td>\n",
       "      <td>-0.737088</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>0.639653</td>\n",
       "      <td>0.292097</td>\n",
       "      <td>-0.500181</td>\n",
       "      <td>0.094142</td>\n",
       "      <td>0.100279</td>\n",
       "      <td>-0.439565</td>\n",
       "      <td>0.160597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.310706</td>\n",
       "      <td>-0.153957</td>\n",
       "      <td>-0.397525</td>\n",
       "      <td>0.163247</td>\n",
       "      <td>0.102393</td>\n",
       "      <td>-0.393191</td>\n",
       "      <td>-0.149867</td>\n",
       "      <td>0.093688</td>\n",
       "      <td>-0.231512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132578</td>\n",
       "      <td>-0.596084</td>\n",
       "      <td>0.520723</td>\n",
       "      <td>0.664362</td>\n",
       "      <td>0.738464</td>\n",
       "      <td>-0.411244</td>\n",
       "      <td>-0.110038</td>\n",
       "      <td>-0.386498</td>\n",
       "      <td>-0.017523</td>\n",
       "      <td>-0.151797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.276156</td>\n",
       "      <td>0.117486</td>\n",
       "      <td>0.097248</td>\n",
       "      <td>-0.301252</td>\n",
       "      <td>-0.194590</td>\n",
       "      <td>-0.149558</td>\n",
       "      <td>-0.705774</td>\n",
       "      <td>-0.121932</td>\n",
       "      <td>0.032583</td>\n",
       "      <td>-0.345269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>-0.890366</td>\n",
       "      <td>0.143492</td>\n",
       "      <td>0.220740</td>\n",
       "      <td>0.490493</td>\n",
       "      <td>0.093366</td>\n",
       "      <td>-0.143799</td>\n",
       "      <td>-0.783927</td>\n",
       "      <td>-0.192266</td>\n",
       "      <td>0.223240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "code                                                                         \n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    -0.365117  0.408025  0.064311 -0.293642  0.103023  0.089713 -0.764232   \n",
       "2    -0.345430  0.288133  0.324433 -0.366527 -0.170981 -0.025718 -0.380066   \n",
       "3     0.000498  0.310706 -0.153957 -0.397525  0.163247  0.102393 -0.393191   \n",
       "4    -0.276156  0.117486  0.097248 -0.301252 -0.194590 -0.149558 -0.705774   \n",
       "\n",
       "             7         8         9    ...           90        91        92  \\\n",
       "code                                  ...                                    \n",
       "0     0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1    -0.003985  0.107479 -0.488348    ...    -0.216967 -0.809641  0.370482   \n",
       "2     0.055025 -0.016809 -0.320237    ...    -0.233300 -0.737088  0.072006   \n",
       "3    -0.149867  0.093688 -0.231512    ...    -0.132578 -0.596084  0.520723   \n",
       "4    -0.121932  0.032583 -0.345269    ...     0.003845 -0.890366  0.143492   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "code                                                                        \n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1     0.632726  0.690164 -0.406542  0.187238 -0.626230 -0.271666  0.082561  \n",
       "2     0.639653  0.292097 -0.500181  0.094142  0.100279 -0.439565  0.160597  \n",
       "3     0.664362  0.738464 -0.411244 -0.110038 -0.386498 -0.017523 -0.151797  \n",
       "4     0.220740  0.490493  0.093366 -0.143799 -0.783927 -0.192266  0.223240  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_matrix = pd.read_csv(\"../../data/FINAL_DATA_1/embedding_matrix.csv\", index_col=0)\n",
    "embedding_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_dict = dict(zip(embedding_matrix.index, embedding_matrix.code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_kmers(seq, kmer=8, max_length=7000):\n",
    "    res = []\n",
    "    i=0\n",
    "    while (i<(len(seq)-kmer)) and (i<max_length):\n",
    "        tmp = seq[i:i+kmer]\n",
    "        if 'N' in tmp:\n",
    "            i+=1\n",
    "            continue\n",
    "        res.append(encoder_dict[tmp])\n",
    "        i+=1\n",
    "    return res\n",
    "\n",
    "X = np.array([make_kmers(v) for k,v in X_tmp])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix.index = embedding_matrix.code\n",
    "embedding_matrix.drop('code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "MAX_SEQUENCE_LENGTH = 7000\n",
    "EMBEDDING_DIM = 100\n",
    "embedding_layer = Embedding(len(embedding_matrix),\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[np.array(embedding_matrix)],\n",
    "#                             input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         6553700   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 6,634,201\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 6,553,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      " 128/9380 [..............................] - ETA: 1344s - loss: 0.7146 - acc: 0.4297"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-30325e7d021c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (9380, 7000)\n",
      "test:  (4620, 7000)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         6553700   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 300)         150300    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 6,704,301\n",
      "Trainable params: 150,601\n",
      "Non-trainable params: 6,553,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 9380 samples, validate on 4620 samples\n",
      "Epoch 1/10\n",
      "9380/9380 [==============================] - 239s - loss: 0.6320 - acc: 0.5386 - val_loss: 0.6153 - val_acc: 0.6617\n",
      "Epoch 2/10\n",
      "9380/9380 [==============================] - 238s - loss: 0.5995 - acc: 0.6943 - val_loss: 0.5980 - val_acc: 0.6944\n",
      "Epoch 3/10\n",
      "9380/9380 [==============================] - 236s - loss: 0.5807 - acc: 0.7472 - val_loss: 0.5824 - val_acc: 0.7353\n",
      "Epoch 4/10\n",
      "9380/9380 [==============================] - 235s - loss: 0.5669 - acc: 0.7662 - val_loss: 0.5681 - val_acc: 0.7615\n",
      "Epoch 5/10\n",
      "9380/9380 [==============================] - 238s - loss: 0.5536 - acc: 0.7765 - val_loss: 0.5586 - val_acc: 0.7626\n",
      "Epoch 6/10\n",
      "9380/9380 [==============================] - 241s - loss: 0.5437 - acc: 0.7783 - val_loss: 0.5479 - val_acc: 0.7712\n",
      "Epoch 7/10\n",
      "9380/9380 [==============================] - 239s - loss: 0.5336 - acc: 0.7786 - val_loss: 0.5407 - val_acc: 0.7716\n",
      "Epoch 8/10\n",
      "9380/9380 [==============================] - 241s - loss: 0.5251 - acc: 0.7814 - val_loss: 0.5329 - val_acc: 0.7723\n",
      "Epoch 9/10\n",
      "9380/9380 [==============================] - 239s - loss: 0.5179 - acc: 0.7789 - val_loss: 0.5272 - val_acc: 0.7732\n",
      "Epoch 10/10\n",
      "9380/9380 [==============================] - 238s - loss: 0.5114 - acc: 0.7781 - val_loss: 0.5242 - val_acc: 0.7736\n",
      "Accuracy: 77.36%\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-61-46d62ca5da5b>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-46d62ca5da5b>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    return model\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# y_train_dumm = np.array(pd.get_dummies(y_train))\n",
    "# y_test_dumm = np.array(pd.get_dummies(y_test))\n",
    "\n",
    "print(\"train: \", X_train.shape)\n",
    "print(\"test: \", X_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(filters=300, kernel_size=5, padding='same', activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "# model.add(LSTM(128)) #,dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=80, validation_data=(X_test, y_test)) #class_weight=Counter(y_train))\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-d634c36288db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv_model_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/fogside/virtualenv/py3/lib/python3.4/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;31m# If file exists and should not be overwritten:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "model.save_weights('conv_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top_words = 60000\n",
    "max_review_length = 5000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
